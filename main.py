"""
Chat OCR API V2 - Session-based Multi-screenshot Management
"""

from fastapi import FastAPI, File, UploadFile, HTTPException, Path as FastAPIPath, Query, Body
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import cv2
import numpy as np
import easyocr
import uuid
import os
from datetime import datetime
from pathlib import Path
import aiofiles
import shutil

# ë¡œì»¬ ëª¨ë“ˆ
from database import Database
from merge_logic import (
    merge_multiple_screenshots,
    deduplicate_messages,
    assign_global_group_ids
)
from external_service import get_external_service

# OCR í•¨ìˆ˜ë“¤ (main_old.pyì—ì„œ í†µí•©)
# get_ocr_reader, detect_chat_bubbles, extract_text_from_roi ë“±ì€ ì•„ë˜ì— ì •ì˜ë¨


# ========== Pydantic Models ==========

class SessionCreateResponse(BaseModel):
    """ì„¸ì…˜ ìƒì„± ì‘ë‹µ"""
    session_id: str
    created_at: str
    status: str


class ScreenshotUploadResponse(BaseModel):
    """ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ ì‘ë‹µ"""
    screenshot_id: str
    session_id: str
    upload_order: int
    processed: bool
    message: str


class MessageModel(BaseModel):
    """ë©”ì‹œì§€ ëª¨ë¸"""
    message_id: str
    text: str
    speaker: str
    confidence: float
    position: Dict[str, float]
    group_id: Optional[int] = None
    score: Optional[float] = None
    emotional_tone: Optional[str] = None
    impact_score: Optional[float] = None
    ai_message: Optional[str] = None


class SessionMessagesResponse(BaseModel):
    """ì„¸ì…˜ ë©”ì‹œì§€ ì¡°íšŒ ì‘ë‹µ"""
    session_id: str
    total_messages: int
    total_screenshots: int
    messages: List[MessageModel]


class ProcessSessionResponse(BaseModel):
    """ì„¸ì…˜ ì²˜ë¦¬ ì‘ë‹µ"""
    session_id: str
    status: str
    total_screenshots: int
    total_messages: int
    merge_info: Dict[str, Any]
    external_api_called: bool


# ========== Configuration ==========

# ì™¸ë¶€ API ì„¤ì •
EXTERNAL_API_URL = "https://db1ef587c833.ngrok-free.app/analyze-messages"
EXTERNAL_API_KEY = None

print(f"ğŸ”§ External API ì„¤ì •:")
if EXTERNAL_API_URL:
    print(f"  - URL: {EXTERNAL_API_URL}")
    print(f"  - API Key: {'ì„¤ì •ë¨' if EXTERNAL_API_KEY else 'ì—†ìŒ'}")
else:
    print(f"  - ë”ë¯¸ ëª¨ë“œ (EXTERNAL_API_URL ì—†ìŒ)")


# ========== FastAPI App ==========

app = FastAPI(
    title="Chat OCR API V2",
    description="ì„¸ì…˜ ê¸°ë°˜ ë‹¤ì¤‘ ìŠ¤í¬ë¦°ìƒ· ë³‘í•© ë° OCR ë¶„ì„ API",
    version="2.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ë³€ìˆ˜
db = Database()
ocr_reader = None
UPLOAD_DIR = Path("uploads_v2")
UPLOAD_DIR.mkdir(exist_ok=True)


# ========== OCR Functions (ìµœì í™”ë¨) ==========

def get_ocr_reader():
    """OCR ë¦¬ë” ì‹±ê¸€í†¤ (ìµœì í™” ë²„ì „)"""
    global ocr_reader
    if ocr_reader is None:
        print("Initializing EasyOCR Reader (Optimized)...")
        ocr_reader = easyocr.Reader(
            ['ko', 'en'],
            gpu=False,  # CPU ì‚¬ìš© (macOSì—ì„œ ë” ë¹ ë¦„)
            download_enabled=False,  # ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ ë°©ì§€
            verbose=False  # ë¡œê·¸ ì¤„ì´ê¸°
        )
        print("EasyOCR Reader initialized successfully")
    return ocr_reader


def is_ui_element_or_noise(text: str, bubble: Dict[str, Any]) -> bool:
    """UI ìš”ì†Œë‚˜ ë…¸ì´ì¦ˆ í…ìŠ¤íŠ¸ í•„í„°ë§"""
    import re
    text_clean = text.strip()

    # UI ìš”ì†Œ
    ui_keywords = ['TALK', 'ë©”ì‹œì§€ ì…ë ¥', 'LTE', 'ê²€ìƒ‰', 'ì„¤ì •']
    if any(keyword in text_clean for keyword in ui_keywords):
        return True

    # ìˆœìˆ˜ ì‹œê°„ë§Œ ìˆëŠ” ê²½ìš°
    if len(text_clean) < 15:
        time_match = re.search(r'(ì˜¤ì „|ì˜¤í›„|AM|PM)?\s*\d{1,2}[:\.]?\d{2}', text_clean)
        if time_match:
            remaining = text_clean.replace(time_match.group(), '').strip()
            if len(remaining) <= 3:
                return True

    # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸
    if len(text_clean) <= 2:
        return True

    # ë‚ ì§œ íŒ¨í„´
    if re.match(r'\d{4}ë…„\s+\d{1,2}ì›”\s+\d{1,2}ì¼', text_clean):
        return True

    return False


def is_repeated_sender_name(text: str, bubble: Dict[str, Any], previous_messages: List[Dict]) -> bool:
    """ë°˜ë³µë˜ëŠ” ë°œì‹ ì ì´ë¦„ í•„í„°ë§"""
    if bubble['bubble_type'] == 'left' and bubble['width'] < 80 and len(text) <= 4:
        recent_texts = [msg['text'] for msg in previous_messages[-3:]]
        if recent_texts.count(text) >= 2:
            return True
        if bubble['height'] < 30 and len(text) <= 5:
            return True
    return False


def detect_chat_bubbles(image: np.ndarray) -> tuple:
    """ì´ë¯¸ì§€ì—ì„œ ì±„íŒ… ë§í’ì„  ì˜ì—­ ê°ì§€"""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    avg_brightness = np.mean(gray)
    is_dark_mode = avg_brightness < 100

    if is_dark_mode:
        _, binary = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)
    else:
        _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)

    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=3)
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)

    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    print(f"  - ì´ {len(contours)}ê°œ ìœ¤ê³½ì„  ë°œê²¬")

    bubbles = []
    img_height, img_width = image.shape[:2]
    filtered_count = {'size': 0, 'area': 0, 'aspect': 0, 'ignored_region': 0}

    TOP_IGNORE_PX = 200
    BOTTOM_IGNORE_PX = 200
    effective_top = TOP_IGNORE_PX
    effective_bottom = img_height - BOTTOM_IGNORE_PX

    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)

        if y < effective_top or (y + h) > effective_bottom:
            filtered_count['ignored_region'] += 1
            continue

        if w < 40 or h < 15:
            filtered_count['size'] += 1
            continue
        if w > img_width * 0.95 or h > img_height * 0.4:
            filtered_count['size'] += 1
            continue

        area = cv2.contourArea(contour)
        if area < 500:
            filtered_count['area'] += 1
            continue

        aspect_ratio = w / h
        if aspect_ratio < 0.3 or aspect_ratio > 15:
            filtered_count['aspect'] += 1
            continue

        center_x = x + w / 2
        bubble_type = 'right' if center_x > img_width * 0.5 else 'left'

        bubbles.append({
            'x': x,
            'y': y,
            'width': w,
            'height': h,
            'bubble_type': bubble_type
        })

    bubbles.sort(key=lambda b: b['y'])
    print(f"  - í•„í„°ë§ë¨: í¬ê¸°({filtered_count['size']}), ë©´ì ({filtered_count['area']}), ì¢…íš¡ë¹„({filtered_count['aspect']}), ë¬´ì‹œëœ ì˜ì—­({filtered_count['ignored_region']})")
    print(f"  - ë³‘í•© ì „ ë§í’ì„ : {len(bubbles)}ê°œ")

    merged_bubbles = merge_nearby_bubbles(bubbles, img_width, img_height)
    print(f"  - ë³‘í•© í›„ ë§í’ì„ : {len(merged_bubbles)}ê°œ")

    return merged_bubbles, binary


def merge_nearby_bubbles(bubbles: List[Dict[str, Any]], img_width: int, img_height: int) -> List[Dict[str, Any]]:
    """ì¸ì ‘í•œ ë§í’ì„  ë³‘í•©"""
    if not bubbles:
        return []

    filtered = []
    for b in bubbles:
        aspect = b['width'] / b['height'] if b['height'] > 0 else 0
        if 0.8 < aspect < 1.2 and b['width'] > 60 and b['height'] > 60:
            continue
        filtered.append(b)

    bubbles = sorted(filtered, key=lambda b: (b['y'], b['x']))

    groups = []
    used = [False] * len(bubbles)

    for i in range(len(bubbles)):
        if used[i]:
            continue

        current_group = [bubbles[i]]
        used[i] = True
        queue = [bubbles[i]]
        head = 0

        while head < len(queue):
            current_bubble = queue[head]
            head += 1

            for j in range(len(bubbles)):
                if used[j]:
                    continue

                other_bubble = bubbles[j]
                y_center_current = current_bubble['y'] + current_bubble['height'] / 2
                y_center_other = other_bubble['y'] + other_bubble['height'] / 2

                is_vertically_close = abs(y_center_current - y_center_other) < (current_bubble['height'] + other_bubble['height']) / 2
                x_dist = max(0, max(current_bubble['x'], other_bubble['x']) - min(current_bubble['x'] + current_bubble['width'], other_bubble['x'] + other_bubble['width']))
                is_horizontally_close = x_dist < 100

                if is_vertically_close and is_horizontally_close:
                    current_group.append(other_bubble)
                    used[j] = True
                    queue.append(other_bubble)

        groups.append(current_group)

    merged = []
    for group in groups:
        if not group:
            continue

        min_x = min(b['x'] for b in group)
        max_x = max(b['x'] + b['width'] for b in group)
        min_y = min(b['y'] for b in group)
        max_y = max(b['y'] + b['height'] for b in group)

        center_x = (min_x + max_x) / 2
        bubble_type = 'right' if center_x > img_width * 0.5 else 'left'

        merged.append({
            'x': min_x,
            'y': min_y,
            'width': max_x - min_x,
            'height': max_y - min_y,
            'bubble_type': bubble_type
        })

    return merged


def extract_text_from_roi(image: np.ndarray, bubble: Dict[str, Any], reader) -> tuple:
    """ROI ì˜ì—­ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìµœì í™”ë¨)"""
    x, y, w, h = bubble['x'], bubble['y'], bubble['width'], bubble['height']

    padding = 5
    x1 = max(0, x - padding)
    y1 = max(0, y - padding)
    x2 = min(image.shape[1], x + w + padding)
    y2 = min(image.shape[0], y + h + padding)

    roi = image[y1:y2, x1:x2]

    if roi.size == 0:
        return "", 0.0

    try:
        results = reader.readtext(
            roi,
            paragraph=False,
            detail=1,
            batch_size=1
        )

        if not results:
            return "", 0.0

        texts = []
        confidences = []

        for detection in results:
            if len(detection) == 3:
                bbox, text, conf = detection
            elif len(detection) == 2:
                text, conf = detection
            else:
                continue

            texts.append(text.strip())
            confidences.append(conf)

        combined_text = ' '.join(texts)
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0

        return combined_text, avg_confidence

    except Exception as e:
        print(f"OCR Error: {e}")
        return "", 0.0


# ========== Helper Functions ==========

def process_single_screenshot(image_path: str) -> List[Dict[str, Any]]:
    """
    ë‹¨ì¼ ìŠ¤í¬ë¦°ìƒ·ì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ (main.py ë¡œì§ ì¬ì‚¬ìš©)

    Args:
        image_path: ì´ë¯¸ì§€ ê²½ë¡œ

    Returns:
        ì¶”ì¶œëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    global ocr_reader

    # ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"Failed to load image: {image_path}")

    # OCR ë¦¬ë” ê°€ì ¸ì˜¤ê¸°
    if ocr_reader is None:
        ocr_reader = get_ocr_reader()

    # ë§í’ì„  ê°ì§€
    bubbles, debug_binary = detect_chat_bubbles(image)
    print(f"  ê°ì§€ëœ ë§í’ì„ : {len(bubbles)}ê°œ")

    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
    messages = []

    for idx, bubble in enumerate(bubbles, 1):
        text, confidence = extract_text_from_roi(image, bubble, ocr_reader)

        if not text:
            continue

        # í•„í„°ë§
        if is_ui_element_or_noise(text, bubble):
            continue

        if is_repeated_sender_name(text, bubble, messages):
            continue

        # speaker ë³€í™˜
        speaker = 'user' if bubble['bubble_type'] == 'right' else 'interlocutor'

        message_data = {
            'text': text,
            'confidence': round(confidence, 3),
            'speaker': speaker,
            'position': {
                'x': float(bubble['x']),
                'y': float(bubble['y']),
                'width': float(bubble['width']),
                'height': float(bubble['height'])
            }
        }
        messages.append(message_data)

    # í›„ì²˜ë¦¬: ë°˜ë³µë˜ëŠ” ë°œì‹ ì ì´ë¦„ ì œê±°
    interlocutor_texts = [
        msg['text'] for msg in messages
        if msg['speaker'] == 'interlocutor' and len(msg['text'].strip()) <= 5
    ]
    text_counts = {text: interlocutor_texts.count(text) for text in set(interlocutor_texts)}
    names_to_filter = {text for text, count in text_counts.items() if count > 1}

    if names_to_filter:
        messages = [
            msg for msg in messages
            if not (msg['speaker'] == 'interlocutor' and msg['text'] in names_to_filter)
        ]

    return messages


# ========== API Endpoints ==========

@app.get("/")
async def root():
    """API ë£¨íŠ¸"""
    return {
        "message": "Chat OCR API V2 - Session-based",
        "version": "2.0.0",
        "endpoints": {
            "POST /sessions": "ìƒˆ ì„¸ì…˜ ìƒì„±",
            "POST /sessions/{session_id}/upload": "ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ",
            "POST /sessions/{session_id}/process": "ì„¸ì…˜ ì²˜ë¦¬ (ë³‘í•© + ì™¸ë¶€ API)",
            "GET /sessions/{session_id}/messages": "ë©”ì‹œì§€ ì¡°íšŒ",
            "POST /sessions/{session_id}/search": "ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ë©”ì‹œì§€ ê²€ìƒ‰",
            "POST /sessions/{session_id}/view": "ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (fuzzy matching)"
        }
    }


@app.post("/sessions", response_model=SessionCreateResponse)
async def create_session():
    """ìƒˆ ì„¸ì…˜ ìƒì„±"""
    session_id = str(uuid.uuid4())

    try:
        session = db.create_session(session_id)
        print(f"âœ“ ì„¸ì…˜ ìƒì„±: {session_id}")

        return SessionCreateResponse(
            session_id=session['session_id'],
            created_at=session['created_at'],
            status=session['status']
        )

    except Exception as e:
        print(f"ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to create session: {str(e)}")


@app.post("/sessions/{session_id}/upload", response_model=ScreenshotUploadResponse)
async def upload_screenshot(
    session_id: str = FastAPIPath(..., description="ì„¸ì…˜ ID"),
    file: UploadFile = File(...)
):
    """
    ì„¸ì…˜ì— ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ

    Args:
        session_id: ì„¸ì…˜ ID
        file: ì´ë¯¸ì§€ íŒŒì¼

    Returns:
        ì—…ë¡œë“œ ê²°ê³¼
    """
    # ì„¸ì…˜ í™•ì¸
    session = db.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")

    # íŒŒì¼ ê²€ì¦
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="Invalid file type")

    try:
        # ì—…ë¡œë“œ ìˆœì„œ ê³„ì‚°
        existing_screenshots = db.get_screenshots(session_id)
        upload_order = len(existing_screenshots) + 1

        # íŒŒì¼ ì €ì¥
        screenshot_id = str(uuid.uuid4())
        file_extension = Path(file.filename).suffix
        filename = f"{session_id}_{upload_order}_{screenshot_id[:8]}{file_extension}"
        file_path = UPLOAD_DIR / filename

        async with aiofiles.open(file_path, 'wb') as out_file:
            content = await file.read()
            await out_file.write(content)

        # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
        image = cv2.imread(str(file_path))
        if image is None:
            raise ValueError("Failed to load image")

        img_height, img_width = image.shape[:2]

        # DBì— ì €ì¥
        screenshot = db.add_screenshot(
            screenshot_id=screenshot_id,
            session_id=session_id,
            file_path=str(file_path),
            upload_order=upload_order,
            image_width=img_width,
            image_height=img_height
        )

        print(f"âœ“ ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ: {filename} (ìˆœì„œ: {upload_order})")

        return ScreenshotUploadResponse(
            screenshot_id=screenshot_id,
            session_id=session_id,
            upload_order=upload_order,
            processed=False,
            message=f"Screenshot uploaded successfully (order: {upload_order})"
        )

    except Exception as e:
        print(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        if file_path.exists():
            file_path.unlink()
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")


@app.post("/sessions/{session_id}/process", response_model=ProcessSessionResponse)
async def process_session(
    session_id: str = FastAPIPath(..., description="ì„¸ì…˜ ID"),
    relationship: str = Query(..., description="ëŒ€í™” ìƒëŒ€ì™€ì˜ ê´€ê³„"),
    relationship_info: str = Query(..., description="ê´€ê³„ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´")
):
    """
    ì„¸ì…˜ ì²˜ë¦¬: OCR â†’ ë³‘í•© â†’ ì™¸ë¶€ API í˜¸ì¶œ

    Args:
        session_id: ì„¸ì…˜ ID
        relationship: ëŒ€í™” ìƒëŒ€ì™€ì˜ ê´€ê³„ (ì˜ˆ: "FRIEND", "SUPERIOR" ë“±)
        relationship_info: ê´€ê³„ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ (ì˜ˆ: "2ë…„ ì§€ê¸°", "ì‹ ì…ì‚¬ì›" ë“±)

    Returns:
        ì²˜ë¦¬ ê²°ê³¼
    """
    # ì„¸ì…˜ í™•ì¸
    session = db.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")

    try:
        print(f"\n{'='*70}")
        print(f"ì„¸ì…˜ ì²˜ë¦¬ ì‹œì‘: {session_id}")
        print(f"{'='*70}")

        # 0. relationship ì •ë³´ ì €ì¥
        db.update_session_relationship(session_id, relationship, relationship_info)
        print(f"  ëŒ€í™” ìƒëŒ€: {relationship} ({relationship_info})")

        # 1. ìŠ¤í¬ë¦°ìƒ· ê°€ì ¸ì˜¤ê¸°
        screenshots = db.get_screenshots(session_id)
        if not screenshots:
            raise HTTPException(status_code=400, detail="No screenshots uploaded")

        print(f"\nğŸ“¸ ì´ {len(screenshots)}ê°œ ìŠ¤í¬ë¦°ìƒ·")

        # 2. ê° ìŠ¤í¬ë¦°ìƒ·ì—ì„œ OCR ìˆ˜í–‰
        all_screenshot_messages = []

        for idx, screenshot in enumerate(screenshots, 1):
            print(f"\n[{idx}/{len(screenshots)}] OCR ì²˜ë¦¬: {Path(screenshot['file_path']).name}")

            messages = process_single_screenshot(screenshot['file_path'])
            print(f"  ì¶”ì¶œëœ ë©”ì‹œì§€: {len(messages)}ê°œ")

            # ë©”ì‹œì§€ì— screenshot_id ì¶”ê°€
            for msg in messages:
                msg['screenshot_id'] = screenshot['screenshot_id']

            all_screenshot_messages.append(messages)
            db.mark_screenshot_processed(screenshot['screenshot_id'])

        # 3. ìŠ¤í¬ë¦°ìƒ· ë³‘í•©
        print(f"\n{'='*70}")
        print("ìŠ¤í¬ë¦°ìƒ· ë³‘í•© ì‹œì‘")
        print(f"{'='*70}")

        merged_messages, merge_history = merge_multiple_screenshots(
            all_screenshot_messages,
            min_overlap=2
        )

        print(f"\në³‘í•© ê²°ê³¼: {len(merged_messages)}ê°œ ë©”ì‹œì§€")

        # 4. ì¤‘ë³µ ì œê±°
        merged_messages = deduplicate_messages(merged_messages)

        # 5. ê·¸ë£¹ ID ì¬í• ë‹¹
        merged_messages = assign_global_group_ids(merged_messages)

        # 6. DBì— ì €ì¥
        print(f"\nğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
        for i, msg in enumerate(merged_messages):
            message_id = str(uuid.uuid4())
            msg['message_id'] = message_id

            db.add_message(
                message_id=message_id,
                session_id=session_id,
                screenshot_id=msg['screenshot_id'],
                text=msg['text'],
                speaker=msg['speaker'],
                confidence=msg['confidence'],
                position_x=msg['position']['x'],
                position_y=msg['position']['y'],
                position_width=msg['position']['width'],
                position_height=msg['position']['height'],
                group_id=msg.get('group_id'),
                sequence_order=i
            )

        # 7. ì™¸ë¶€ API í˜¸ì¶œ (user ë©”ì‹œì§€ì— score/ai_message ì¶”ê°€)
        print(f"\n{'='*70}")
        print("ì™¸ë¶€ ì„œë²„ ì—°ë™")
        print(f"{'='*70}")

        external_service = get_external_service(
            api_url=EXTERNAL_API_URL,
            api_key=EXTERNAL_API_KEY
        )
        score_results = await external_service.get_scores_for_messages(
            merged_messages,
            relationship=relationship,
            relationship_info=relationship_info
        )

        if score_results:
            # API ì‘ë‹µì„ DB ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜
            transformed_results = []
            for res in score_results:
                transformed_results.append({
                    'group_id': res.get('group_id'),
                    'score': res.get('appropriateness_rating'),  # appropriateness_ratingì„ scoreë¡œ ë§¤í•‘
                    'emotional_tone': res.get('emotional_tone'),
                    'impact_score': res.get('impact_score'),
                    'review_comment': res.get('review_comment'),
                    'suggested_alternative': res.get('suggested_alternative'),
                })
            
            db.bulk_update_scores_by_group(session_id, transformed_results)
            print(f"âœ“ {len(transformed_results)}ê°œ ê·¸ë£¹ì— score ì—…ë°ì´íŠ¸ ì™„ë£Œ")

        # 8. ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        db.update_session_counts(session_id)
        db.update_session_status(session_id, 'completed')

        print(f"\n{'='*70}")
        print(f"âœ“ ì„¸ì…˜ ì²˜ë¦¬ ì™„ë£Œ: {session_id}")
        print(f"{'='*70}\n")

        return ProcessSessionResponse(
            session_id=session_id,
            status='completed',
            total_screenshots=len(screenshots),
            total_messages=len(merged_messages),
            merge_info={
                'merge_history': merge_history,
                'total_merged': len(merged_messages)
            },
            external_api_called=len(score_results) > 0
        )

    except Exception as e:
        print(f"\nâŒ ì„¸ì…˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        db.update_session_status(session_id, 'failed')
        raise HTTPException(status_code=500, detail=f"Processing failed: {str(e)}")


@app.get("/sessions/{session_id}/messages", response_model=SessionMessagesResponse)
async def get_session_messages(session_id: str = FastAPIPath(..., description="ì„¸ì…˜ ID")):
    """
    ì„¸ì…˜ì˜ ë©”ì‹œì§€ ì¡°íšŒ

    Args:
        session_id: ì„¸ì…˜ ID

    Returns:
        ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    session = db.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")

    try:
        messages = db.get_messages(session_id, order_by='sequence_order')
        screenshots = db.get_screenshots(session_id)

        message_models = [
            MessageModel(
                message_id=msg['message_id'],
                text=msg['text'],
                speaker=msg['speaker'],
                confidence=msg['confidence'],
                position=msg['position'],
                group_id=msg.get('group_id'),
                score=msg.get('score'),
                emotional_tone=msg.get('emotional_tone'),
                impact_score=msg.get('impact_score'),
                ai_message=msg.get('review_comment')  # review_commentë¥¼ ai_messageë¡œ ë§¤í•‘
            )
            for msg in messages
        ]

        return SessionMessagesResponse(
            session_id=session_id,
            total_messages=len(messages),
            total_screenshots=len(screenshots),
            messages=message_models
        )

    except Exception as e:
        print(f"ë©”ì‹œì§€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get messages: {str(e)}")


@app.post("/sessions/{session_id}/search")
async def search_by_screenshot(
    session_id: str = FastAPIPath(..., description="ì„¸ì…˜ ID"),
    file: UploadFile = File(...)
):
    """
    ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ë©”ì‹œì§€ ê²€ìƒ‰ (OCR ì—†ì´ ê¸°ì¡´ ë°ì´í„°ì—ì„œ ì°¾ê¸°)

    Args:
        session_id: ì„¸ì…˜ ID
        file: ê²€ìƒ‰ìš© ìŠ¤í¬ë¦°ìƒ·

    Returns:
        ë§¤ì¹­ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    session = db.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")

    if session['status'] != 'completed':
        raise HTTPException(status_code=400, detail="Session not processed yet")

    try:
        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = UPLOAD_DIR / f"search_{uuid.uuid4()}{Path(file.filename).suffix}"
        async with aiofiles.open(temp_path, 'wb') as out_file:
            content = await file.read()
            await out_file.write(content)

        # ê°„ë‹¨í•œ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        print(f"ğŸ” ê²€ìƒ‰ìš© ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ì¤‘...")
        search_messages = process_single_screenshot(str(temp_path))

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        temp_path.unlink()

        if not search_messages:
            return JSONResponse(content={
                "matched": False,
                "message": "No messages found in search screenshot",
                "results": []
            })

        # DBì—ì„œ ë§¤ì¹­ë˜ëŠ” ë©”ì‹œì§€ ì°¾ê¸°
        all_messages = db.get_messages(session_id)
        matched_messages = []

        print(f"  ê²€ìƒ‰ ë©”ì‹œì§€: {len(search_messages)}ê°œ")
        print(f"  ì„¸ì…˜ ë©”ì‹œì§€: {len(all_messages)}ê°œ")

        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë§¤ì¹­
        for search_msg in search_messages:
            for db_msg in all_messages:
                if search_msg['text'] == db_msg['text'] and search_msg['speaker'] == db_msg['speaker']:
                    matched_messages.append(db_msg)
                    break

        print(f"  âœ“ ë§¤ì¹­ëœ ë©”ì‹œì§€: {len(matched_messages)}ê°œ")

        return JSONResponse(content={
            "matched": len(matched_messages) > 0,
            "message": f"Found {len(matched_messages)} matching messages",
            "results": matched_messages
        })

    except Exception as e:
        print(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        if temp_path.exists():
            temp_path.unlink()
        raise HTTPException(status_code=500, detail=f"Search failed: {str(e)}")


@app.post("/sessions/{session_id}/view")
async def view_by_screenshots(
    session_id: str = FastAPIPath(..., description="ì„¸ì…˜ ID"),
    files: List[UploadFile] = File(..., description="ì¡°íšŒìš© ìŠ¤í¬ë¦°ìƒ·ë“¤")
):
    """
    ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ì´ë¯¸ ë¶„ì„ëœ ë©”ì‹œì§€ ì¡°íšŒ (Fuzzy matching ì§€ì›)

    - ì—¬ëŸ¬ ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ ê°€ëŠ¥
    - OCR ìˆ˜í–‰ í›„ DBì˜ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì™€ fuzzy matching
    - ë§¤ì¹­ëœ ë©”ì‹œì§€ë§Œ ë°˜í™˜ (AI ë¶„ì„ ê²°ê³¼ í¬í•¨)
    - ë§¤ì¹­ ì•ˆëœ ë©”ì‹œì§€ëŠ” ì œì™¸

    Args:
        session_id: ì„¸ì…˜ ID
        files: ì¡°íšŒìš© ìŠ¤í¬ë¦°ìƒ· íŒŒì¼ë“¤

    Returns:
        ë§¤ì¹­ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (AI ë¶„ì„ ê²°ê³¼ í¬í•¨)
    """
    from difflib import SequenceMatcher

    session = db.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")

    if session['status'] != 'completed':
        raise HTTPException(status_code=400, detail="Session not processed yet. Please call /process first.")

    try:
        print(f"\n{'='*70}")
        print(f"View ìš”ì²­: {session_id}")
        print(f"{'='*70}")
        print(f"ğŸ“¸ ì—…ë¡œë“œëœ ìŠ¤í¬ë¦°ìƒ·: {len(files)}ê°œ")

        # 1. ì„ì‹œ íŒŒì¼ ì €ì¥ ë° OCR ì²˜ë¦¬
        temp_paths = []
        all_view_messages = []

        for idx, file in enumerate(files, 1):
            # ì„ì‹œ íŒŒì¼ ì €ì¥
            temp_path = UPLOAD_DIR / f"view_{uuid.uuid4()}{Path(file.filename).suffix}"
            async with aiofiles.open(temp_path, 'wb') as out_file:
                content = await file.read()
                await out_file.write(content)
            temp_paths.append(temp_path)

            # OCR ì²˜ë¦¬
            print(f"\n[{idx}/{len(files)}] OCR ì²˜ë¦¬: {file.filename}")
            messages = process_single_screenshot(str(temp_path))
            print(f"  ì¶”ì¶œëœ ë©”ì‹œì§€: {len(messages)}ê°œ")
            all_view_messages.extend(messages)

        print(f"\nì´ OCR ì¶”ì¶œ ë©”ì‹œì§€: {len(all_view_messages)}ê°œ")

        # 2. DBì—ì„œ ê¸°ì¡´ ë¶„ì„ëœ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        db_messages = db.get_messages(session_id, order_by='sequence_order')
        print(f"DB ì €ì¥ëœ ë©”ì‹œì§€: {len(db_messages)}ê°œ")

        # 3. Fuzzy matchingìœ¼ë¡œ ë§¤ì¹­
        def text_similarity(text1: str, text2: str) -> float:
            """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
            return SequenceMatcher(None, text1, text2).ratio()

        matched_results = []
        SIMILARITY_THRESHOLD = 0.85  # 85% ì´ìƒ ìœ ì‚¬í•˜ë©´ ë§¤ì¹­

        for view_msg in all_view_messages:
            best_match = None
            best_score = 0.0

            for db_msg in db_messages:
                # speaker ì¼ì¹˜ í™•ì¸
                if view_msg['speaker'] != db_msg['speaker']:
                    continue

                # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = text_similarity(view_msg['text'], db_msg['text'])

                if similarity > best_score:
                    best_score = similarity
                    best_match = db_msg

            # ì„ê³„ê°’ ì´ìƒì´ë©´ ë§¤ì¹­ ì„±ê³µ
            if best_match and best_score >= SIMILARITY_THRESHOLD:
                # ì¤‘ë³µ ì œê±° (ì´ë¯¸ ì¶”ê°€ëœ message_idëŠ” ìŠ¤í‚µ)
                if not any(m['message_id'] == best_match['message_id'] for m in matched_results):
                    matched_results.append(best_match)
                    print(f"  âœ“ ë§¤ì¹­: '{view_msg['text'][:30]}...' â†’ '{best_match['text'][:30]}...' (ìœ ì‚¬ë„: {best_score:.2f})")

        # 4. ì„ì‹œ íŒŒì¼ ì‚­ì œ
        for temp_path in temp_paths:
            if temp_path.exists():
                temp_path.unlink()

        # 5. ê²°ê³¼ ì •ë ¬ (sequence_order ê¸°ì¤€)
        matched_results.sort(key=lambda x: x.get('sequence_order', 0))

        print(f"\nâœ“ ìµœì¢… ë§¤ì¹­ëœ ë©”ì‹œì§€: {len(matched_results)}ê°œ")
        print(f"{'='*70}\n")

        # 6. Response ìƒì„±
        message_models = [
            {
                'message_id': msg['message_id'],
                'text': msg['text'],
                'speaker': msg['speaker'],
                'confidence': msg['confidence'],
                'position': msg['position'],
                'group_id': msg.get('group_id'),
                'score': msg.get('score'),
                'emotional_tone': msg.get('emotional_tone'),
                'impact_score': msg.get('impact_score'),
                'ai_message': msg.get('review_comment'),
                'suggested_alternative': msg.get('suggested_alternative')
            }
            for msg in matched_results
        ]

        return JSONResponse(content={
            "session_id": session_id,
            "matched": len(matched_results) > 0,
            "total_matched": len(matched_results),
            "total_ocr_extracted": len(all_view_messages),
            "messages": message_models
        })

    except Exception as e:
        print(f"\nâŒ View ì‹¤íŒ¨: {e}")
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for temp_path in temp_paths:
            if temp_path.exists():
                temp_path.unlink()
        raise HTTPException(status_code=500, detail=f"View failed: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=80,
        reload=True
    )
